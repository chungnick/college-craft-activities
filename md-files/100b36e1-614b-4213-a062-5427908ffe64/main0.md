[Skip to the content](#site-content)

* [Home](https://encore.ucsd.edu/)
  + [Sponsors](#)
    - [Industry](https://encore.ucsd.edu/partners/)
  + [Mailing List](https://encore.ucsd.edu/mailing-list/)
* [Team](https://encore.ucsd.edu/about-encore/)
  + [Advisory Board](https://encore.ucsd.edu/advisory-board/)
  + [Affiliated Faculty](https://encore.ucsd.edu/affiliated-faculty/)
  + [EnCORE Alumni](https://encore.ucsd.edu/encore-alumni/)
  + [EnCORE Postdocs](https://encore.ucsd.edu/encore-postdocs/)
  + [EnCORE Students](https://encore.ucsd.edu/encore-students/)
  + [Job Opportunities](https://encore.ucsd.edu/job-opportunities/)
  + [Leadership](https://encore.ucsd.edu/leadership/)
  + [Staff](https://encore.ucsd.edu/staff/)
* [News](https://encore.ucsd.edu/news/)
* [Education](https://encore.ucsd.edu/education-2/)
  + [Capstone Projects](https://encore.ucsd.edu/capstone-projects/)
* [Research](https://encore.ucsd.edu/research/)
  + [EnCORE Visitors Program](https://encore.ucsd.edu/encore-visitors-program/)
  + [Publications](https://encore.ucsd.edu/publications/)
  + [Research Highlights](https://encore.ucsd.edu/research-highlights/)
  + [Recordings](https://www.youtube.com/channel/UC2gWrPPj8EFhEyKuWRk00QA)
* [Events](https://encore.ucsd.edu/events/)
  + [EnCORE Seminar](https://encore.ucsd.edu/encore-seminar/)
  + [EnCORE Student Social](https://encore.ucsd.edu/encore-student-meet/)
    - [Fall 2024](https://encore.ucsd.edu/encore-student-seminars/)
    - [Spring 2024](https://encore.ucsd.edu/encore-student-meet-spring-2024/)
    - [Fall 2023](https://encore.ucsd.edu/encore-student-meet-fall-2023/)
    - [Spring 2023](https://encore.ucsd.edu/encore-student-meet-spring-2023/)
  + [EnCORE Tutorials](https://encore.ucsd.edu/encore-tutorials/)
  + [EnCORE Visitors Program](https://encore.ucsd.edu/encore-visitors-program/)
  + [EnCORE Workshops](https://encore.ucsd.edu/events/encore-workshops/)
    - [2022 Workshops](https://encore.ucsd.edu/events/2022-events/)
      * [Communication Efficient Distributed Optimization](https://sites.google.com/ucsd.edu/cedo/home)
      * [Compression + Computation 2022](https://sites.google.com/view/compression-computation-2022)
      * [EnCORE Fall Retreat 2022](https://encore.ucsd.edu/event/)
    - [2023 Workshops](https://encore.ucsd.edu/events/2023-workshops/)
      * [Distributed Learning & Decision Making](https://encore.ucsd.edu/encore-ita-2023/)
      * [EnCORE Annual Retreat 2023](https://encore.ucsd.edu/annual-retreat/)
      * [EnCORE Collaboration Workshop 2023](https://encore.ucsd.edu/collaboration-workshop-2023/)
    - [2024 Workshops](https://encore.ucsd.edu/events/2024-workshops/)
      * [Collaboration Workshop Spring ’24](https://encore.ucsd.edu/collaboration-workshop-spring-2024/)
      * [Collaboration Workshop Fall ’24](https://encore.ucsd.edu/fall-collaboration-workshop/)
      * [EnCORE IPAM Workshop on Computational & Statistical Gap](https://encore.ucsd.edu/ipam-workshop/)
      * [Industry Day 2024](https://encore.ucsd.edu/industry-day-2024/)
      * [NSF TRIPODS Workshop](https://encore.ucsd.edu/nsf-tripods-workshop/)
      * [Old Questions and New Directions in Theory of Clustering](https://encore.ucsd.edu/clustering-san-diego/)
    - [2025 Workshops](https://encore.ucsd.edu/events/2025-workshops/)
      * [Fine-Grained Complexity](https://encore.ucsd.edu/fine-grained-complexity/)
      * [Foundations of Fairness and Accountability Workshop](https://sites.google.com/view/fairness-workshop?usp=sharing)
      * [Meta-Complexity Workshop](https://encore.ucsd.edu/meta-complexity-workshop/)
      * [Theoretical Perspectives on LLMs](https://encore.ucsd.edu/workshop-on-theoretical-perspectives-on-llms/)
      * [Workshop on Defining Holistic Private Data Science for Practice](https://encore.ucsd.edu/privacy-workshop/)
    - [EnCORE Research Highlights](https://encore.ucsd.edu/encore-research-highlights/)
  + [Foundations of Data Science Virtual Series](https://sites.google.com/view/dstheory)
    - [Adversarial Robust Streaming](https://sites.google.com/view/dstheory/past-talks_1/adversarial-streaming?authuser=0)
    - [Theory of Large ML Models](https://sites.google.com/view/dstheory/past-talks_1/theory-of-lms?authuser=0)
      * [The Puzzle of Dimensionality and Feature Learning in Neural Networks and Kernel Machines](https://encore.ucsd.edu/the-puzzle-of-dimensionality-and-feature-learning-in-neural-networks-and-kernel-machines/)
      * [Deep Generative Models and Inverse Problems for Signal Reconstruction](https://encore.ucsd.edu/deep-generative-models-talk/)
      * [Theoretical Exploration of Foundation Model Adaptation Methods](https://encore.ucsd.edu/theoretical-exploration-of-foundation-model-adaptation-methods/)
      * [Scaling Data-Constrained Language Model](https://encore.ucsd.edu/scaling-data-constrained-language-model/)
      * [The Uneasy Relation Between Deep Learning and Statistics](https://encore.ucsd.edu/the-uneasy-relation-between-deep-learning-and-statistics/)
* [Opportunities](#)
  + [External Visitors Program](https://encore.ucsd.edu/encore-visitors-program/)
  + [Postdoctoral Positions](https://encore.ucsd.edu/job-opportunities/)
* [Outreach](https://encore.ucsd.edu/outreach/)
  + [K-12](#)
    - [Elementary School Outreach](https://encore.ucsd.edu/elementary-school-outreach/)
      * [Empowering Young Minds: Robotic Arts and Craft Workshop for Elementary School Kids](https://encore.ucsd.edu/empowering-young-minds/)
      * [Robotic Arts and Crafts](https://encore.ucsd.edu/robotic-arts-and-crafts/)
    - [Middle School Outreach](https://encore.ucsd.edu/middle-school-outreach/)
      * [TEAMS Program](https://encore.ucsd.edu/teams-program/)
      * [Middle School ML Program](https://encore.ucsd.edu/middle-school-ml-game-workshop/)
    - [High School Outreach](https://encore.ucsd.edu/high-school-outreach/)
      * [High School Visit Day](https://encore.ucsd.edu/encore-high-school-visit-day/)
      * [High School Hands-on Activities](https://encore.ucsd.edu/art-field-trip/)
      * [FinDS](https://encore.ucsd.edu/finds-2/)
        + [FinDS – Beginner’s Program](https://encore.ucsd.edu/finds-beginners-program/)
        + [FinDS – Advanced Program](https://encore.ucsd.edu/finds-advanced-program/)
          - [FinDS Advanced Lectures](https://encore.ucsd.edu/finds-advanced-lectures-2024/)
        + [Event Archive](#)
          - [FinDS 2023](https://encore.ucsd.edu/finds-2023/)
            * [FinDS Lectures](https://encore.ucsd.edu/finds-lectures/)
      * [Interactive Coding Tutorial](https://encore.ucsd.edu/interactive-coding-tutorial/)
      * [Polynomial Regression Tool](https://czye17.github.io/polynomial-regression/)
  + [College Outreach](https://encore.ucsd.edu/outreach/college-outreach/)
    - [EnIAC](https://encore.ucsd.edu/eniac/)
    - [Rising Stars in Data Science](https://encore.ucsd.edu/rising-stars-in-data-science/)
      * [Rising Stars in Data Science 2024 – Applications and Info Session](https://encore.ucsd.edu/rising-stars-in-data-science-2024-applications-and-info-session/)
      * [Rising Stars in Data Science 2023](https://encore.ucsd.edu/rising-stars-2023/)
    - [Science Like Me](https://www.uctv.tv/education/science-like-me/)

Menu

* [Home](https://encore.ucsd.edu/)
  + [Sponsors](#)
    - [Industry](https://encore.ucsd.edu/partners/)
  + [Mailing List](https://encore.ucsd.edu/mailing-list/)
* [Team](https://encore.ucsd.edu/about-encore/)
  + [Advisory Board](https://encore.ucsd.edu/advisory-board/)
  + [Affiliated Faculty](https://encore.ucsd.edu/affiliated-faculty/)
  + [EnCORE Alumni](https://encore.ucsd.edu/encore-alumni/)
  + [EnCORE Postdocs](https://encore.ucsd.edu/encore-postdocs/)
  + [EnCORE Students](https://encore.ucsd.edu/encore-students/)
  + [Job Opportunities](https://encore.ucsd.edu/job-opportunities/)
  + [Leadership](https://encore.ucsd.edu/leadership/)
  + [Staff](https://encore.ucsd.edu/staff/)
* [News](https://encore.ucsd.edu/news/)
* [Education](https://encore.ucsd.edu/education-2/)
  + [Capstone Projects](https://encore.ucsd.edu/capstone-projects/)
* [Research](https://encore.ucsd.edu/research/)
  + [EnCORE Visitors Program](https://encore.ucsd.edu/encore-visitors-program/)
  + [Publications](https://encore.ucsd.edu/publications/)
  + [Research Highlights](https://encore.ucsd.edu/research-highlights/)
  + [Recordings](https://www.youtube.com/channel/UC2gWrPPj8EFhEyKuWRk00QA)
* [Events](https://encore.ucsd.edu/events/)
  + [EnCORE Seminar](https://encore.ucsd.edu/encore-seminar/)
  + [EnCORE Student Social](https://encore.ucsd.edu/encore-student-meet/)
    - [Fall 2024](https://encore.ucsd.edu/encore-student-seminars/)
    - [Spring 2024](https://encore.ucsd.edu/encore-student-meet-spring-2024/)
    - [Fall 2023](https://encore.ucsd.edu/encore-student-meet-fall-2023/)
    - [Spring 2023](https://encore.ucsd.edu/encore-student-meet-spring-2023/)
  + [EnCORE Tutorials](https://encore.ucsd.edu/encore-tutorials/)
  + [EnCORE Visitors Program](https://encore.ucsd.edu/encore-visitors-program/)
  + [EnCORE Workshops](https://encore.ucsd.edu/events/encore-workshops/)
    - [2022 Workshops](https://encore.ucsd.edu/events/2022-events/)
      * [Communication Efficient Distributed Optimization](https://sites.google.com/ucsd.edu/cedo/home)
      * [Compression + Computation 2022](https://sites.google.com/view/compression-computation-2022)
      * [EnCORE Fall Retreat 2022](https://encore.ucsd.edu/event/)
    - [2023 Workshops](https://encore.ucsd.edu/events/2023-workshops/)
      * [Distributed Learning & Decision Making](https://encore.ucsd.edu/encore-ita-2023/)
      * [EnCORE Annual Retreat 2023](https://encore.ucsd.edu/annual-retreat/)
      * [EnCORE Collaboration Workshop 2023](https://encore.ucsd.edu/collaboration-workshop-2023/)
    - [2024 Workshops](https://encore.ucsd.edu/events/2024-workshops/)
      * [Collaboration Workshop Spring ’24](https://encore.ucsd.edu/collaboration-workshop-spring-2024/)
      * [Collaboration Workshop Fall ’24](https://encore.ucsd.edu/fall-collaboration-workshop/)
      * [EnCORE IPAM Workshop on Computational & Statistical Gap](https://encore.ucsd.edu/ipam-workshop/)
      * [Industry Day 2024](https://encore.ucsd.edu/industry-day-2024/)
      * [NSF TRIPODS Workshop](https://encore.ucsd.edu/nsf-tripods-workshop/)
      * [Old Questions and New Directions in Theory of Clustering](https://encore.ucsd.edu/clustering-san-diego/)
    - [2025 Workshops](https://encore.ucsd.edu/events/2025-workshops/)
      * [Fine-Grained Complexity](https://encore.ucsd.edu/fine-grained-complexity/)
      * [Foundations of Fairness and Accountability Workshop](https://sites.google.com/view/fairness-workshop?usp=sharing)
      * [Meta-Complexity Workshop](https://encore.ucsd.edu/meta-complexity-workshop/)
      * [Theoretical Perspectives on LLMs](https://encore.ucsd.edu/workshop-on-theoretical-perspectives-on-llms/)
      * [Workshop on Defining Holistic Private Data Science for Practice](https://encore.ucsd.edu/privacy-workshop/)
    - [EnCORE Research Highlights](https://encore.ucsd.edu/encore-research-highlights/)
  + [Foundations of Data Science Virtual Series](https://sites.google.com/view/dstheory)
    - [Adversarial Robust Streaming](https://sites.google.com/view/dstheory/past-talks_1/adversarial-streaming?authuser=0)
    - [Theory of Large ML Models](https://sites.google.com/view/dstheory/past-talks_1/theory-of-lms?authuser=0)
      * [The Puzzle of Dimensionality and Feature Learning in Neural Networks and Kernel Machines](https://encore.ucsd.edu/the-puzzle-of-dimensionality-and-feature-learning-in-neural-networks-and-kernel-machines/)
      * [Deep Generative Models and Inverse Problems for Signal Reconstruction](https://encore.ucsd.edu/deep-generative-models-talk/)
      * [Theoretical Exploration of Foundation Model Adaptation Methods](https://encore.ucsd.edu/theoretical-exploration-of-foundation-model-adaptation-methods/)
      * [Scaling Data-Constrained Language Model](https://encore.ucsd.edu/scaling-data-constrained-language-model/)
      * [The Uneasy Relation Between Deep Learning and Statistics](https://encore.ucsd.edu/the-uneasy-relation-between-deep-learning-and-statistics/)
* [Opportunities](#)
  + [External Visitors Program](https://encore.ucsd.edu/encore-visitors-program/)
  + [Postdoctoral Positions](https://encore.ucsd.edu/job-opportunities/)
* [Outreach](https://encore.ucsd.edu/outreach/)
  + [K-12](#)
    - [Elementary School Outreach](https://encore.ucsd.edu/elementary-school-outreach/)
      * [Empowering Young Minds: Robotic Arts and Craft Workshop for Elementary School Kids](https://encore.ucsd.edu/empowering-young-minds/)
      * [Robotic Arts and Crafts](https://encore.ucsd.edu/robotic-arts-and-crafts/)
    - [Middle School Outreach](https://encore.ucsd.edu/middle-school-outreach/)
      * [TEAMS Program](https://encore.ucsd.edu/teams-program/)
      * [Middle School ML Program](https://encore.ucsd.edu/middle-school-ml-game-workshop/)
    - [High School Outreach](https://encore.ucsd.edu/high-school-outreach/)
      * [High School Visit Day](https://encore.ucsd.edu/encore-high-school-visit-day/)
      * [High School Hands-on Activities](https://encore.ucsd.edu/art-field-trip/)
      * [FinDS](https://encore.ucsd.edu/finds-2/)
        + [FinDS – Beginner’s Program](https://encore.ucsd.edu/finds-beginners-program/)
        + [FinDS – Advanced Program](https://encore.ucsd.edu/finds-advanced-program/)
          - [FinDS Advanced Lectures](https://encore.ucsd.edu/finds-advanced-lectures-2024/)
        + [Event Archive](#)
          - [FinDS 2023](https://encore.ucsd.edu/finds-2023/)
            * [FinDS Lectures](https://encore.ucsd.edu/finds-lectures/)
      * [Interactive Coding Tutorial](https://encore.ucsd.edu/interactive-coding-tutorial/)
      * [Polynomial Regression Tool](https://czye17.github.io/polynomial-regression/)
  + [College Outreach](https://encore.ucsd.edu/outreach/college-outreach/)
    - [EnIAC](https://encore.ucsd.edu/eniac/)
    - [Rising Stars in Data Science](https://encore.ucsd.edu/rising-stars-in-data-science/)
      * [Rising Stars in Data Science 2024 – Applications and Info Session](https://encore.ucsd.edu/rising-stars-in-data-science-2024-applications-and-info-session/)
      * [Rising Stars in Data Science 2023](https://encore.ucsd.edu/rising-stars-2023/)
    - [Science Like Me](https://www.uctv.tv/education/science-like-me/)

## FinDS

FinDS is a 3-week summer program that is designed to provide high school students a strong base in the Mathematical Foundations of Data Science, with in-person and virtual options available.

FinDS offers two tracks: Beginners and Advanced. Learn more about these two tracks below and **v****isit**[**mathfinds.ucsd.edu**](http://mathfinds.ucsd.edu)**for more details.**

##

**DETAILS:**

* July 31, 2023 - June 16, 2025 (Advanced Track) & June 2, 2025 - June 20, 2025 (Level 1 Track)
* CSE Building at UC San Diego, UPENN, or Online

[Learn More](https://mathfinds.ucsd.edu/)

### FinDS Tracks

### Prospective Students

Application Requirements

What's Next

Application Requirements

The applications for the FinDS programs are out now! In order to apply, you must have the following:

1. A personal statement in the form of a PDF less than 10MB.
2. An unofficial transcript in the form of a PDF less than 10MB.
3. At least 1 letter of recommendation from a STEM teacher by providing that teacher’s email address. **This letter of recommendation needs to be sent in by the application deadline.**

The application for the **Beginner’s Program** can be found [here](https://forms.gle/NxS74sPGW1jwdU65A).

The application for the **Advanced Program** can be found [here](https://forms.gle/EjbAzbUNRpg8yb6H7).

**Apply online by May 1, 2024 to be considered for the program.**

What's Next

Congratulations on being admitted to the FinDS program. Here are some next steps to be mindful of:

* Tuition
* Directions to campus for those who are participating in-person
* Zoom links for those who are participating virtually
* Materials (In-person)

  + Notebook
  + Pencil
* Materials (Virtual)

  + Notebook
  + Pencil
  + Zoom-accessible device, preferably a laptop

**Participants have 1 week\* from the date they are informed of admission to submit tuition.**

If you are in need of financial support, we offer assistance contingent on justified need. Please apply for this support via this [Google Form](https://urldefense.com/v3/__https://forms.gle/cd2udf3oCZCYNDkv9__;!!Mih3wA!G6VqsIV3EzPiHP21rPreJb3rLEQvQayFTUzRrjAwG1xphk_3ApaK38aXRMiPfi-hF7WoRNSzX4LzZWBDVg$) by **May 21**.

**Important Dates:**

Application Deadline: May 1, 2024

Financial Aid Application Deadline: May 21, 2024

Admission Notification\*: May 15, 2024

Financial Aid Decision Notification: May 23, 2024

\*Unless the participant is receiving a scholarship, each group has 1 week to submit tuition. A generous number of scholarships are available from the National Science Foundation.

### Past FinDS Programs

* [FinDS 2023](https://encore.ucsd.edu/finds-2023/)

### Instructors

## [Dr. Rajiv Gandhi, Lead Instructor](https://ccanonne.github.io/)

###### Professor at the University Of pennsylvania, Rutgers University-Camden

Professor Rajiv Gandhi, Professor of Computer Science at Rutgers University-Camden, and lecturer at the University of Pennsylvania. He received his Ph.D. in Computer Science from the University of Maryland in 2003. He also worked as a software engineer at Qualcomm from 1994-96.

His research interests are Algorithm Design, Combinatorial Optimization, and Probabilistic methods. He is a passionate educator and has worked with students with varied backgrounds, and he received the Provost’s Award for Teaching Excellence at Rutgers–Camden in 2006. He received a Fulbright fellowship to teach in Mumbai, India from Jan-May 2011. Prof. Gandhi has also received the [2022 ACM-SIGACT Distinguished Service Award](https://sigact.org/prizes/service/2022.html).

## [Barna Saha, Instructor](https://ccanonne.github.io/)

###### Professor at the University of california, san diego

Barna Saha is the E Guber Endowed Chair Associate Professor of UCSD CSE and HDSI. Before joining UCSD, she was an Associate Professor at UC Berkeley. Saha’s primary research focus is on Theoretical Computer Science, specifically Algorithm Design. She is passionate about diversity and teaching, and seeing students succeed from all backgrounds. She is a recipient of the Presidential Early Career Award (PECASE)- the highest honor given by the White House to early career scientists, a Sloan fellowship, an NSF CAREER Award, and multiple paper awards. [Learn More.](https://barnasaha.net/)

## [Kamalika Chaudhuri, Instructor](https://ccanonne.github.io/)

###### Professor at the University of California, San Diego and Research Scientist at Meta AI

Kamalika Chaudhuri is a machine learning researcher. She is interested in the foundations of trustworthy machine learning — such as robust machine learning, learning with privacy and out-of-distribution generalization. She received her Ph.D. from University of California Berkeley. [Learn More.](https://cseweb.ucsd.edu/~kamalika/)

## [Sanjoy Dasgupta, Instructor](https://ccanonne.github.io/)

###### Professor at the University of California, San Diego

Sanjoy Dasgupta is a Professor in the Department of Computer Science and Engineering at UC San Diego. He received his PhD from Berkeley in 2000, and spent two years at AT&T Research Labs before joining UCSD. His area of research is algorithmic statistics, with a focus on unsupervised and minimally supervised learning. [Learn More.](https://cseweb.ucsd.edu/~dasgupta/)

## [Arya Mazumdar, Instructor](https://ccanonne.github.io/)

###### Professor at the university of california, san diego

Arya Mazumdar is an associate professor of UCSD HDSI, and an affiliate faculty member of Computer Science & Engineering. He obtained his Ph.D. degree from University of Maryland, College Park (2011) specializing in information theory. Subsequently Arya was a postdoctoral scholar at Massachusetts Institute of Technology (2011-2012), an assistant professor in University of Minnesota (2013-2015), and an assistant followed by associate professor in University of Massachusetts Amherst (2015-2021). Arya is a recipient of multiple awards, including a Distinguished Dissertation Award for his Ph.D. thesis (2011), the NSF CAREER award (2015), an EURASIP JSAP Best Paper Award (2020), and the IEEE ISIT Jack K. Wolf Student Paper Award (2010). He is currently serving as an Associate Editor for the IEEE Transactions on Information Theory and as an Area editor for Now Publishers Foundation and Trends in Communication and Information Theory series. Arya’s research interests include coding theory (error-correcting codes and related combinatorics), information theory, statistical learning and distributed optimization.  [Learn More.](https://mazumdar.ucsd.edu/)

## [Gal Mishne, Instructor](https://ccanonne.github.io/)

###### Professor at the University Of California, San Diego

Gal Mishne is an Assistant Professor of HDSI. Mishne’s research is at the intersection of signal processing and machine learning for graph-based modeling, processing and analysis of large-scale high-dimensional real-world data. She develops unsupervised and generalizable methods that allow the data to reveal its own story in an unbiased manner. Her research includes anomaly detection and clustering in remote sensing imagery, manifold learning on multiway data tensors with biomedical applications, and computationally efficient application of spectral methods. Most recently her research has focused on unsupervised data analysis in neuroscience, from processing of raw neuroimaging data through discovery of neural manifolds to visualization of learning in neural networks. [Learn More.](http://mishne.ucsd.edu/)

## [Yusu Wang, Instructor](https://ccanonne.github.io/)

###### Professor at the University of California, San Diego

Yusu Wang is a Professor of HDSI. She obtained her PhD degree from Duke University in 2004, and from 2004 – 2005, she was a post-doctoral fellow at Stanford University. Prior to joining UC San Diego, Yusu Wang was a Professor of Computer Science and Engineering Department at the Ohio State University, where she also co-directed the Foundations of Data Science Research CoP (Community of Practice) at Translational Data Analytics Institute (TDAI@OSU) from 2018–2020. Yusu Wang primarily works in the field of geometric and topological data analysis. She is particularly interested in developing effective and theoretically justified algorithms for data analysis using geometric and topological ideas and methods, as well as in applying them to practical domains. Very recently she has been exploring how to combine geometric and topological ideas with machine learning frameworks for modern data science. Yusu Wang received the Best PhD Dissertation Award from the Computer Science Department at Duke University. She also received DOE Early Career Principal Investigator Award in 2006, and NSF Career Award in 2008. Her work received several best paper awards. She is currently on the editorial boards for SIAM Journal on Computing (SICOMP), Computational Geometry: Theory and Applications (CGTA), and Journal of Computational Geometry (JoCG). [Learn More.](http://yusu.belkin-wang.org/)

## Online Covering: Secretaries, Prophets, and Samples

###### Gregory Kehne

**Abstract**: We give a polynomial-time algorithm for online covering IPs with a competitive ratio of O(log mn) when the constraints are revealed in random order, essentially matching the best possible offline bound of Omega(\og n) and circumventing the Omega(log m log n) lower bound known in adversarial order. We then leverage this O(log mn) competitive algorithm for the prophet version of online integer covering, where constraints are sampled from a sequence of known distributions. Our reduction in fact relies only on samples from these distributions, in a manner evocative of prior work on single-sample prophet inequalities in the packing setting. We present sample guarantees in the prophet setting, as well as in the setting where random samples from an adversarial instance are revealed at the outset.

This talk is based on joint work with Anupam Gupta and Roie Levin.

## EIFFeL: Ensuring Integrity for Federated Learning

###### Amrita Roy Chowdhury

**Abstract**: Federated learning (FL) is a decentralized learning paradigm where multiple clienst collaborate with a server to train a machine learning model. To ensure privacy, the server performs secure aggregation of model updates from the clients. Unfortunately, this prevents verification of the well-formedness (integrity) of the updates as the updates are masked. Consequently, malformed updates designed to poison the model can be injected without detection. In this talk, I will formalize the problem of ensuring both update privacy and integrity in FL and present a new system, EIFFeL, that enables secure aggregation of verified updates. EIFFeL is a general framework that can enforce arbitrary integrity checks and remove malformed updates from the aggregate, without violating privacy. Further, EIFFeL is practical for real-world usage. For instance, with 100 clients and 10% poisoning, EIFFeL can train an MNIST classification model to the same accuracy as that of a non-poisoned federated learner in just 2.4s per iteration.

## Fair, Low-Cost Hierarchical Clustering

###### Marina Knittel

**Abstract**: This talk will cover three papers that explore fair, low-cost hierarchical clustering. Ahmadian et al. [2020] initiates the study of fair hierarchical clustering by extending Chierichetti et al.’s [2019] notion of representationally proportional flat clustering to the hierarchical setting. They create the first approximation algorithm for the problem – a highly theoretical O(n^{5/6} log^{3/2} n) approximation, reflecting the difficulty of the problem. This is improved in two follow-up works to a near, and then eventually true, polylogarithmic approximation. We discuss general techniques proposed in these works and how they are used to achieve fairness with limited increase in cost.

## Faster Approximate All Pairs Shortest Paths

###### Christopher Ye

**Abstract**: The all pairs shortest path problem (APSP) is one of the foundational problems in computer science. Given a graph, the goal is to compute distance d(u, v) between all pairs of vertices. On undirected, unweighted graphs, Seidel’s algorithm shows that computing APSP exactly is equivalent to matrix multiplication. Naturally, the search for faster algorithms then must turn to approximate computations. A solution D is (a, b)-approximate if d(u, v) <= D(u, v) <= a d(u, v) + b for all pairs u, v. There has been a long line of work in computing approximate APSP. Dor, Halperin, and Zwick provided a framework obtaining increasingly faster algorithms with increasingly large additive errors in 2000, a framework which has resisted improvement for over two decades. Leveraging fast matrix multiplication, Deng et al. improved the running time for the specific case of (1, 2) from O(n^{7/3}) to O(n^{2.26}), where the stated bound uses a matrix multiplication algorithm due to Durr. Recently, Roditty obtained a O(n^{9/4}) time (2, 0) approximation. In this talk I present a multitude of new approximation algorithms for the APSP problem, obtaining significant improvements in both multiplicative and additive approximations.

Joint work with Barna Saha.

## Monotonicity Testing and Isoperimetry on the Hypergrid

###### Hadley Black

**Abstract**

The problem of monotonicity testing is a central problem in the area of property testing which asks us to design a randomized algorithm which can distinguish monotone functions from functions which are far from being monotone. Over the last 20 years a series of beautiful results have unearthed a connection between monotonicity testing and isoperimetric inequalities on the Boolean hypercube. Isoperimetric inequalities give a way of relating the boundary and volume of a set; a famous example is due to Talagrand from 1993. It turns out that the key to analyzing monotonicity testers has been to prove isoperimetric inequalities in the directed hypercube. This culminated in the seminal work of Khot, Minzer, and Safra (STOC 2015) who showed a directed version of Talagrand’s inequality, which they used to obtain an optimal tester for Boolean functions.

The goal of our work is to extend this amazing connection beyond just the hypercube. Towards this, we prove a directed version of Talagrand’s inequality which generalizes the result of Khot, Minzer, and Safra to hypergrids and use this inequality to obtain the first monotonicity tester for Boolean functions on the hypergrid with the optimal dependence on the dimension.

**Based on joint work with D. Chakrabarty (Dartmouth) and C. Seshadhri (UCSC) to appear in STOC 2023**

#### [Demystifying Disagreement-on-the-Line in High Dimensions](https://arxiv.org/abs/2301.13371)

###### Donghwan Lee

**Abstract**:

Evaluating the performance of machine learning models under distribution shift is challenging, especially when we only have unlabeled data from the shifted (target) domain, along with labeled data from the original (source) domain. Recent work suggests that the notion of disagreement, the degree to which two models trained with different randomness differ on the same input, is a key to tackle this problem. Experimentally, disagreement and prediction error have been shown to be strongly connected, which has been used to estimate model performance. Experiments have led to the discovery of the disagreement-on-the-line phenomenon, whereby the classification error under the target domain is often a linear function of the classification error under the source domain; and whenever this property holds, disagreement under the source and target domain follow the same linear relation. In this work, we develop a theoretical foundation for analyzing disagreement in high-dimensional random features regression; and study under what conditions the disagreement-on-the-line phenomenon occurs in our setting. Experiments on CIFAR-10-C, Tiny ImageNet-C, and Camelyon17 are consistent with our theory and support the universality of the theoretical findings.

## Tractable Agreement Protocols via Calibration

###### Natalie Collina (UPenn)

**Abstract**:

We give an efficient reduction through which any machine learning algorithm can be converted into an interactive protocol that can interact with a human decision maker to improve their predictions. In the interactive protocol, the machine learning model first produces a prediction, which implies a recommended action for the human decision maker. The human can update their beliefs as a function of the recommendation they received, but can also incorporate their own knowledge and observations, and so may disagree with the provided recommendation. The human then responds to the model’s recommendation by conveying either agreement with the model’s recommendation, or directional disagreement. The model then updates its state and provides a new recommendation, and the human may in turn again update their beliefs given the new information they have learned from the model. The process continues until the model and the human reach agreement. We show that any predictive model can be efficiently turned into an agreement protocol (without reducing its accuracy) so that the number of rounds until the protocol reaches agreement is small, under forgiving, computationally tractable assumptions on the human’s decision making process. Additionally, the final decisions are guaranteed to be more accurate than either those of the model or of the human on their own. In fact, the assumptions we make on the human would be satisfied by a Bayesian decision maker, but are a substantial relaxation that makes them algorithmically tractable and do not require perfect Bayesian rationality. In this way we generalize Aumann’s agreement theorem from requiring Bayesian rationality to requiring only tractable calibration conditions, and generalize known quantitative versions of the theorem to hold for multi-dimensional expectations and more general forms of communication.

## FairProof : Confidential and Certifiable Fairness for Neural Networks

###### Chhavi Yadav (UCSD)

**Abstract**:

Machine learning models are increasingly used in societal applications, yet legal and privacy concerns demand that they very often be kept confidential. Consequently, there is a growing distrust about the fairness properties of these models in the minds of consumers, who are often at the receiving end of model predictions. To this end, we propose Fairproof – a system that uses Zero-Knowledge Proofs (a cryptographic primitive) to publicly verify the fairness of a model, while maintaining confidentiality. We also propose a fairness certification algorithm for fully-connected neural networks which is befitting to ZKPs and is used in this system. We implement Fairproof in Gnark and demonstrate empirically that our system is practically feasible..

## Distances on Markov Chains and their Differentiation

###### Tristan Brugere (UCSD)

**Abstract**: (Directed) graphs with node attributes are a common type of data in various applications and there is a vast literature on developing metrics and efficient algorithms for comparing them.

Recently, in the graph learning and optimization communities, a range of new approaches have been developed for comparing graphs with node attributes, leveraging ideas such as the Optimal Transport (OT) and the Weisfeiler-Lehman (WL) graph isomorphism test.  
Two state-of-the-art representatives are the OTC distance proposed in (O’Connor et al., 2022) and the WL distance in (Chen et al., 2022).

Interestingly, while these two distances are developed based on different ideas, we observe that they both view graphs as Markov chains and are deeply connected. Indeed, in this paper, we propose a unified framework to generate distances for Markov chains (thus including (directed) graphs with node attributes), which we call the Optimal Transport Markov (OTM) distances, that encompass both the OTC and the WL distances. We further introduce a special one-parameter family of distances within our OTM framework, called the discounted WL distance. We show that the discounted WL distance has nice theoretical properties and can address several limitations of the existing OTC and WL distances. Furthermore, contrary to the OTC and the WL distances, our new discounted WL distance can be differentiated after an entropy-regularization similar to the Sinkhorn distance, making it suitable to use in learning frameworks, e.g., as the reconstruction loss in a graph generative model.

## Nonlinear Spiked Random Matrix Models: From Signal Recovery to Deep Learning Theory

###### Behrad Moniri (UPenn)

**Abstract**: In this talk, we first propose a nonlinear spiked random matrix model where a nonlinear function is applied elementwise to a rank-one perturbation of a random matrix. We then study the spectrum of this model in different regimes of signal strength. Finally, we use these results to study low-rank signal recovery given nonlinear noisy observations, as well as feature learning in two-layer neural networks after one step of gradient descent.

**Bio**: Behrad is a PhD student in the Department of Electrical and Systems Engineering at the University of Pennsylvania. His current research interests are deep learning theory, probability theory, and information theory. Behrad received his B.Sc. degree in Electrical Engineering from the Sharif University of Technology in 2020 with highest distinctions.

## Building Collaborative Intelligence

###### Sai Praneeth Karimireddy (UC Berkeley)

**Abstract**: How do we build ML systems that put the interests of users and society front and center? Using collaborations with [Doctors Without Borders](https://urldefense.com/v3/__https://www.msf.org/__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dhGlfh5eU$) and the [Cancer Registry of Norway](https://urldefense.com/v3/__https://www.kreftregisteret.no/en/__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dh8AfkOwg$) as case studies, we will show how **collaborative learning (CL)**can be used to build such user-centric ML systems**.** CL techniques (including decentralized and federated learning) allow us to train ML models without the users sacrificing their privacy or ownership and control over their data.  Yet for these systems to truly succeed, two fundamental challenges must be confronted. These systems need to be efficient and **scale to massive networks,** and manage and resolve the **conflicting goals**of the participants. We will discuss how tools from optimization, statistics, and economics can be leveraged to address these challenges.

**Bio**: [Sai Praneeth Karimireddy](https://urldefense.com/v3/__https://spkreddy.org/__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dhjU5BLVA$) is a postdoc at UC Berkeley with [Mike I. Jordan](https://urldefense.com/v3/__https://people.eecs.berkeley.edu/*jordan/__;fg!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dh7ejuJOc$) and obtained his PhD from EPFL with [Martin Jaggi](https://urldefense.com/v3/__https://www.epfl.ch/labs/mlo/__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dhfgCdLsw$). His research builds large-scale collaborative learning systems and has seen widespread real-world adoption both by public health organizations (e.g., [Doctors Without Borders](https://urldefense.com/v3/__https://www.msf.org/__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dhGlfh5eU$), the [Red Cross](https://urldefense.com/v3/__https://www.icrc.org/en__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dh6CEDFcI$), the [Cancer Registry of Norway](https://urldefense.com/v3/__https://www.kreftregisteret.no/en/__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dh8AfkOwg$)) and by industries such as [Meta](https://urldefense.com/v3/__https://actu.epfl.ch/news/using-the-matrix-to-help-meta-gear-up/__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dhSrCgpQw$), [Google](https://urldefense.com/v3/__https://github.com/google/fedjax__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dhIZC__EY$), [OpenAI](https://urldefense.com/v3/__https://arxiv.org/pdf/2102.12092.pdf__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dhIIg5jUE$), and [Owkin](https://urldefense.com/v3/__https://www.owkin.com/__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dhI10WTxs$). His research has been recognized by the EPFL [Patrick Denantes Memorial Prize](https://urldefense.com/v3/__https://actu.epfl.ch/news/patrick-denantes-memorial-prize-2022/__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dha7Th1oQ$) for the best thesis in computer science, the [Chorafas Foundation Award](https://urldefense.com/v3/__https://actu.epfl.ch/news/dimitris-n-chorafas-foundation-award-2021-sai-pran/__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dhkqB4cpQ$) for exceptional applied research, an EPFL [thesis distinction award](https://urldefense.com/v3/__https://www.epfl.ch/education/phd/phd-awards/thesis-distinction/__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dh3a9Iu4Q$), an [SNSF fellowship](https://urldefense.com/v3/__https://www.snf.ch/en/XIZpfY3iVS5KRRoD/funding/careers/postdoc-mobility__;!!Mih3wA!EES8pW4aGjlghdPVlKXvnKPBM2OzkS1ciBUW-qcn-quaV0XlC-NQ5eReMxS3ahY-WN8FRIcmIohupAgEx7dhD-ST2O0$), and multiple best paper awards.

## Collaborative Compressors in Distributed Mean Estimation with Limited Communication Budget

###### Harshvardhan (UCSD)

**Abstract**: Distributed high dimensional mean estimation is a common aggregation routine used often in distributed optimization methods (e.g. federated learning). In light of these applications, recently there has been an interest in distributed mean estimation in a communication-constrained setting, where vectors have to be compressed before sharing. However,  in these applications the vectors whose mean are to be estimated are often correlated with each other. To exploit these correlations, recently Suresh et al., 2022, Jhunjhunwala et al., 2021, Jiang et al, 2023, proposed multiple  correlation aware compression schemes. However, any theoretical analysis of graceful degradation of these correlation-aware compression schemes with increasing heterogeneity (de-correlation) is absent in  the literature. Moreover, the correlations have to be known for these schemes to work. In this paper, we propose collaborative compression schemes that agnostically exploit the correlation among vectors in a distributed setting. We propose modifications of 4 different compression schemes to make them suitable for distributed mean estimation. Our schemes are all based on and/or variants of popular sign-based compression (signSGD and 1 bit compressed sensing). We do a rigorous theoretical analysis of our proposed schemes to show how the estimation error varies with the degree of correlation among vectors. In the process, we come up with appropriate correlation measures for these applications as well. Further, we compare the performance of our schemes to existing benchmarks for distributed mean estimation and for downstream distributed learning tasks.

## No Fear of Large Number of Local Steps: Leveraging Implicit Bias on FedAvg Algorithm

###### Heng Zhu (UCSD)

**Abstract**: In federated learning, a large number of local steps is usually avoided due to data heterogeneity. However, in this work we leverage the implicit bias of gradient descent to show that a federated approach involving a large number of local steps can closely approximate the centralized solution obtained by training on aggregated data. We investigate  this phenomenon through experiments conducted on synthetic data using both linear and logistic regression models. Furthermore, we offer a theoretical explanation for the linear regression task.

## Product Manifold Learning with Independent Coordinate Selection

###### Jesse He (UCSD)

**Abstract**: In many dimensionality reduction tasks, we wish to identify the constituent components that explain our observations. For manifold learning, this can be formalized as factoring a Riemannian product manifold. Recovering this factorization, however, may suffer from certain difficulties in practice, especially when data is sparse or noisy, or when one factor is distorted by the other. To address these limitations, we propose identifying non-redundant coordinates on the product manifold before applying product manifold learning to identify which coordinates correspond to different factor manifolds.

## Tear and Repulsion Enabled Registration of Point Clouds for Manifold Learning

###### Dhruv Kohli (UCSD)

**Abstract**: We present a framework for aligning the local views of a possibly closed/non-orientable data manifold to produce an embedding in its intrinsic dimension through tearing. Through a spectral coloring scheme, we render the embeddings of the points across the tear with matching colors, enabling a visual recovery of the topology of the data manifold. The embedding is further equipped with a tear-aware metric that enables computation of shortest paths while accounting for the tear. To measure the quality of an embedding, we propose two Lipschitz-type notions of global distortion—a stronger and a weaker one—along with their pointwise counterparts for a finer assessment of the embedding. Subsequently, we bound them using the distortion of the local views and the alignment error between them. We show that our theoretical result on strong distortion leads to a new perspective on the need for a repulsion term in manifold learning objectives. As a result, we enhance our alignment approach by incorporating repulsion. Finally, we compare various strategies for the tear and repulsion enabled alignment, with regard to their speed of convergence and the quality of the embeddings produced.

This is joint work with my advisors Gal Mishne and Alex Cloninger at UCSD.

## Efficient Online Clustering with Moving Costs

###### Dimitrios Christou (UT Austin)

**Abstract**: In this talk, I will consider an online-learning problem, called Online Clustering with Moving Costs, at which a learner maintains a set of facilities over rounds so as to minimize the connection cost of an adversarially selected sequence of clients. The learner is informed on the positions of the clients at each round only after its facility-selection and can use this information to update its decision in the next round. However, updating the facility positions comes with an additional moving cost based on the moving distance of the facilities. I will be presenting the first (polynomial-time) approximate-regret algorithm for this setting through a combination of different algorithmic techniques such as HST embeddings, the FTRL framework with a dilated entropic regulariser as well as a novel rounding scheme.

## Encoding Structural Symmetry is Key for Length Generalization in Arithmetic Tasks

###### Mahdi Sabbaghi (UPenn)

**Abstract**: Despite the success of Transformers on language understanding, code generation, and logical reasoning, they still fail to (length) generalize on basic arithmetic tasks such as addition and multiplication. A major reason behind this failure is the vast difference in structure of numbers versus text; for example, numbers are associated with a specific significance order that plays a role in calculating the answer. In contrast, for text, such symmetries are quite unnatural. In this work, we propose to encode these semantics explicitly into the model via appropriate data formatting and custom positional encodings. To further elucidate the importance of explicitly encoding structure, in a simplified linear setting, we prove that standard positional encodings even when trained with augmentations to implicitly induce structure fail at such generalization, whereas enforcing structure via positional encodings succeeds.

**Bio**: Mahdi Sabbaghi is a second year PhD student at UPenn, department of Electrical and System Engineering, supervised by Professors Hamed Hassani and George Pappas. Previously he obtained a B. Sc. degree in Electrical Engineering as well as a B. Sc. degree in Physics from the Sharif University of Technology, in Tehran.

## Private Estimation of U Statistics

###### Shourya Pandey (UT Austin)

**Abstract**: We consider the problem of private estimation of U statistics. U statistics are widely used estimators that naturally arise in a broad class of problems, from nonparametric signed rank tests to subgraph counts in random networks. Despite the recent outpouring of interest in private mean estimation, private algorithms for more general U statistics have received little attention.  We propose a framework where, for a broad class of U statistics, one can use existing tools in private mean estimation to obtain confidence intervals where the private error does not overwhelm the irreducible error resulting from the variance of the U statistics. However, in specific cases that arise when the U statistics degenerate or have vanishing moments, the private error may be of a larger order than the non-private error. To remedy this, we propose a new thresholding-based approach that uses Hajek projections to re-weight different subsets. As we show,  this leads to more accurate inference in certain settings.

## Finite-Time Logarithmic Bayes Regret Upper Bounds

###### Alexia Atsidakou (UT Austin)

**Abstract**: We derive the first finite-time logarithmic Bayes regret upper bounds for Bayesian bandits, for BayesUCB and Thompson Sampling. In Gaussian and Bernoulli multi-armed bandits, we obtain $O(c\_\Delta \log n)$ and $O(c\_h \log^2 n)$ upper bounds for an upper confidence bound algorithm, where $c\_h$ and $c\_\Delta$ are constants depending on the prior distribution and the gaps of bandit instances sampled from it, respectively. The latter bound asymptotically matches the lower bound of Lai (1987). Our proofs are a major technical departure from prior works, while being simple and general. The key idea in our proofs is to conduct a frequentist per-instance analysis with Bayesian confidence intervals, and then integrate it over the prior.

Our results provide insights on the value of prior in the Bayesian setting, both in the objective and as a side information given to the learner. They significantly improve upon existing $\tilde{O}(\sqrt{n})$ bounds, which have become standard in the literature despite the logarithmic lower bound of Lai (1987).

## Pareto-Optimal Algorithms for Learning in Games

###### Natalie Collina and Eshwar Ram Arunachaleswaran

**Abstract**: We study the problem of characterizing optimal learning algorithms for playing repeated games against an adversary with unknown payoffs. In this problem, the first player (called the learner) commits to a learning algorithm against a second player (called the optimizer), and the optimizer best-responds by choosing the optimal dynamic strategy for their (unknown but well-defined) payoff. Classic learning algorithms (such as no-regret algorithms) provide some counterfactual guarantees for the learner, but might perform much more poorly than other learning algorithms against particular optimizer payoffs.  
  
In this paper, we introduce the notion of asymptotically Pareto-optimal learning algorithms. Intuitively, if a learning algorithm is Pareto-optimal, then there is no other algorithm which performs asymptotically at least as well against all optimizers and performs strictly better (by at least $\Omega(T)$) against some optimizer. We show that well-known no-regret algorithms such as Multiplicative Weights and Follow The Regularized Leader are Pareto-dominated. However, while no-regret is not enough to ensure Pareto-optimality, we show that a strictly stronger property, no-swap-regret, is a sufficient condition for Pareto-optimality.  
  
Proving these results requires us to address various technical challenges specific to repeated play, including the fact that there is no simple characterization of how optimizers who are rational in the long-term best-respond against a learning algorithm over multiple rounds of play. To address this, we introduce the idea of the asymptotic menu of a learning algorithm: the convex closure of all correlated distributions over strategy profiles that are asymptotically implementable by an adversary. Interestingly, we show that all no-swap-regret algorithms share the same asymptotic menu, implying that all no-swap-regret algorithms are “strategically equivalent”.  
  
This talk is based on work with Jon Schneider.

## Metric Learning from Lazy Crowds

###### Geelon So

**Abstract**: We consider crowd-based metric learning from preference comparisons, where given two items, a user prefers the item that is closer to their latent ideal item. Here, “closeness” is measured with respect to a shared but unknown Mahalanobis distance. Can we recover this distance when we can only obtain very few responses per user?  
  
In this very low-budget regime, we show that generally, nothing at all about the metric is revealed, even with infinitely many users. But when the items have subspace cluster structure, we present a divide-and-conquer approach for metric recovery, and provide theoretical recovery guarantees and empirical validation.  
  
This is joint work with Zhi Wang (UCSD) and Ramya Korlakai Vinayak (UW–Madison).

## Random Walks, Conductance, and Resistance for the Connection Graph Laplacian

###### Zhengchao Wan

**Abstract**: We investigate the concept of effective resistance in connection graphs, expanding its traditional application from undirected graphs. We propose a robust definition of effective resistance in connection graphs by focusing on the duality of Dirichlet-type and Poisson-type problems on connection graphs. Additionally, we delve into random walks, taking into account both node transitions and vector rotations. This approach introduces novel concepts of effective conductance and resistance matrices for connection graphs, capturing mean rotation matrices corresponding to random walk transitions. Thereby, it provides new theoretical insights for network analysis and optimization.  
  
This is based on a joint work with Alexander Cloninger, Gal Mishne, Andreas Oslandsbotn, Sawyer Jack Robertson and Yusu Wang.

## Approximability and Inapproximability of Strict-CSPs

###### Akbar Rafiey

**Abstract**: We study the approximability and inapproximability of Strict-CSPs. An instance of the Strict-CSPs consists of a set of constraints over a set of variables and a cost function over the assignments. The goal is to find an assignment to the variables of minimum cost which satisfies all the constraints. Some prominent problems that this framework captures are (Hypergraph) Vertex Cover, Min Sum k-Coloring, Multiway Cut, Min Ones, and others.  
  
We focus on a systematic study of Strict-CSPs of the form Strict-CSPs(H), that is, Strict-CSPs where the type of constraints is limited to predicates from a set H. Our first result is a dichotomy for approximation of Strict-CSPs(H), where H is a binary predicate, i.e., a digraph. We prove that if digraph H has bounded width, then Strict-CSPs(H) is approximable within a constant factor (depending on H); otherwise, there is no approximation for Strict-CSPs(H) unless P=NP.  
  
Second, we study the inapproximability of Strict-CSP and present the first general hardness of approximation for Strict-CSP. More precisely, we prove a dichotomy theorem that states every instance of Strict-CSP(H) (H being a digraph) is either polynomial-time solvable or APX-complete. Moreover, we show the existence of a universal constant 0<\delta<1 such that it is NP-hard to approximate Strict-CSP(H) within a factor of (2-\delta) for all digraphs H where Strict-CSP(H) is NP-complete.

## Buy-many Mechanisms for Many Unit-demand Buyers

###### Rojin Rezvan

**Abstract**: A recent line of research has established a novel desideratum for designing approximatelyrevenue-optimal multi-item mechanisms, namely the buy-many constraint. Under this constraint, prices for different allocations made by the mechanism must be subadditive implying that the price of a bundle cannot exceed the sum of prices of individual items it contains. This natural constraint has enabled several positive results in multi-item mechanism design bypassing well-established impossibility results. Our work addresses a main open question from this literature involving the design of buymany mechanisms for multiple buyers. Our main result is that a simple sequential item pricing mechanism with buyer-specific prices can achieve an O(log m) approximation to the revenue of any buy-many mechanism when all buyers have unit-demand preferences over m items. This is the best possible as it directly matches the previous results for the single-buyer setting where no simple mechanism can obtain a better approximation. Our result applies in full generality: even though there are many alternative ways buy-many mechanisms can be defined for multibuyer settings, our result captures all of them at the same time. We achieve this by directly competing with a more permissive upper-bound on the buy-many revenue, obtained via an ex-ante relaxation.

## Streaming PCA for Markovian Data

###### Syamantak Kumar

**Abstract**: Since its inception in 1982, Oja’s algorithm has become an established method for streaming principle component analysis (PCA). We study the problem of streaming PCA, where the data-points are sampled from an irreducible, aperiodic, and reversible Markov chain. Our goal is to estimate the top eigenvector of the unknown covariance matrix of the stationary distribution. This setting has implications in scenarios where data can solely be sampled from a Markov Chain Monte Carlo (MCMC) type algorithm, and the objective is to perform inference on parameters of the stationary distribution. Most convergence guarantees for Oja’s algorithm in the literature assume that the data-points are sampled IID. For data streams with Markovian dependence, one typically downsamples the data to get a “nearly” independent data stream. In this paper, we obtain the first sharp rate for Oja’s algorithm on the entire data, where we remove the logarithmic dependence on the sample size, resulting from throwing data away in downsampling strategies.

## A d^{1/2 + o(1)} Monotonicity Tester for Boolean Functions on d-Dimensional Hypergrids

###### Hadley Black

**Abstract**: Monotonicity testing of Boolean functions over the n-width, d-dimensional hypergrid is a classic problem in property testing, where the goal is to design a randomized algorithm which can distinguish monotone functions from those which are far from any monotone function while making as few queries as possible. The special case of n = 2 corresponds to the hypercube domain. Here a long line of works exploiting a very interesting connection with isoperimetric inequalities for Boolean functions culminated in a non-adaptive tester making ~O(d^{1/2}) queries in a celebrated paper by Khot, Minzer, and Safra (SICOMP 2018). This is known to be optimal for non-adaptive testers. However, the general case of hypergrids for n > 2 remained open. Very recently, two papers (Black-Chakrabarty-Seshadhri STOC 2023 and Braverman-Khot-Kindler-Minzer ITCS 2023) independently obtained ~O(poly(n) d^{1/2}) query testers for hypergrids. These results are essentially optimal for n < polylog(d), but are far from optimal for n >> polylog(d).  
  
This talk covers our most recent result (appearing at FOCS 2023) which obtains a non-adaptive d^{1/2+o(1)} query tester for all n, resolving the non-adaptive monotonicity testing problem for hypergrids, up to a factor of d^{o(1)}. Our proof relies on many new techniques as well as two key theorems which we proved in earlier works from SODA 2020 and STOC 2023.

## SmoothLLMs: Defending LLMs against Adversarial Attacks

###### Alex Robey

**Abstract**: Despite efforts to align large language models (LLMs) with human values, widely-used LLMs such as GPT, Llama, Claude, and PaLM are susceptible to jailbreaking attacks, wherein an adversary fools a targeted LLM into generating objectionable content.  To address this vulnerability, we propose SmoothLLM, the first algorithm designed to mitigate jailbreaking attacks on LLMs.  Based on our finding that adversarially-generated prompts are brittle to character-level changes, our defense first randomly perturbs multiple copies of a given input prompt, and then aggregates the corresponding predictions to detect adversarial inputs.  SmoothLLM reduces the attack success rate on numerous popular LLMs to below one percentage point, avoids unnecessary conservatism, and admits provable guarantees on attack mitigation.  Moreover, our defense uses exponentially fewer queries than existing attacks and is compatible with any LLM.

## Composition of Nested Embeddings with an Application to Outlier Removal

###### Kristin Sheridan

**Abstract**: We study the design of embeddings into Euclidean space with outliers. Given a metric space $(X,d)$ and an integer $k$, the goal is to embed all but $k$ points in $X$ (called the “”outliers””) into $\ell\_2$ with the smallest possible distortion $c$. Finding the optimal distortion $c$ for a given outlier set size $k$, or alternately the smallest $k$ for a given target distortion $c$ are both NP-hard problems. In fact, it is UGC-hard to approximate $k$ to within a factor smaller than $2$ even when the metric sans outliers is isometrically embeddable into $\ell\_2$. We consider bi-criteria approximations. Our main result is a polynomial time algorithm that approximates the outlier set size to within an $O(\log^2 k)$ factor and the distortion to within a constant factor.  
  
The main technical component in our result is an approach for constructing a composition of two given embeddings from subsets of $X$ into $\ell\_2$ which inherits the distortions of each to within small multiplicative factors. Specifically, given a low $c\_S$ distortion embedding from $S\subset X$ into $\ell\_2$ and a high(er) $c\_X$ distortion embedding from the entire set $X$ into $\ell\_2$, we construct a single embedding that achieves the same  distortion $c\_S$ over pairs of points in $S$ and an expansion of at most $O(\log k)\cdot c\_X$ over the remaining pairs of points, where $k=|X\setminus S|$. Our composition theorem extends to embeddings into arbitrary $\ell\_p$ metrics for $p\ge 1$, and may be of independent interest. While unions of embeddings over disjoint sets have been studied previously, to our knowledge, this is the first work to consider compositions of {\em nested} embeddings.

## Graph Sparsification by Approximate Matrix Multiplication

###### Neo Charalambides

**Abstract**:  Graphs arising in statistical problems, signal processing, large networks, combinatorial optimization, and data analysis are often dense, which causes both computational and storage bottlenecks. One way of sparsifying a weighted graph, while sharing the same vertices as the original graph but reducing the number of edges, is through spectral sparsification. We study this problem through the perspective of RandNLA. Specifically, we utilize randomized matrix multiplication to give a clean and simple analysis of how sampling according to edge weights gives a spectral approximation to graph Laplacians, without requiring spectral information. Through the CR−MM algorithm, we attain a simple and computationally efficient sparsifier whose resulting Laplacian estimate is unbiased and of minimum variance. Furthermore, we define a new notion of additive spectral sparsifiers, which has not been considered in the literature.

## Talk Title

###### Student Name

Abstract

* [Cendanatoto](https://elsa.org/)
* [Situs Toto](https://test.elearning3.clioedu.it/)
* <http://earthlearning.unimol.it/>
* <https://flz.sabu.edu.ly/>
* [Cendanatoto](https://www.geovap.com/)
* [Cendanatoto](https://aviation.edu.my//)
* [Slot Thailand](https://exam.aviation.edu.my/)
* [Cendanatoto](https://crystallography.icmab.es/)
* [Slot Gacor](https://elijo.umpwr.ac.id/)
* [Slot Gacor](https://bappelitbangda.tasikmalayakab.go.id/)
* [Toto Slot](https://fst.ulb.ac.id/)
* [Toto Slot](https://www.eahealth.org/)
* [Cendanatoto](https://ejer.com.tr/)
* [Slot Gacor](https://simanila.unila.ac.id/)
* [Slot Dana](https://p3m.polsri.ac.id/)
* [Cendanatoto](https://sala.fecomercio.com.br/)
* [Cendanatoto](https://madagascar-groupejcr.com/)
* [Kementerian Pemberdayaan Perempuan dan Perlindungan Anak Indonesia](https://kemenpppa.id/)
* [BRIN - Badan Riset dan Inovasi Nasional](https://brin.id/)
* [Cendanatoto](https://aseansinglewindow.org/)
* [Toto Togel](https://rlec.pt/)
* [https://wapresi.id](https://wapresi.id/)
* <https://liputannewstoday.id/>
* [pedia288](https://kemkes-kaltim.id/)
* [pedia288](https://fh.ulb.ac.id/)
* [Cendanatoto](https://paribalii.org/)
* [Cendanatoto](https://ppid.kemenpppa.id/)
* [Cendanatoto](https://hipmikalimantan.org/)
* [Cendanatoto](https://pafisontang.org/)
* <https://kemkessumut.id/>
* <https://maritimeacademy.id/>
* <https://kadinlanggur.id/>
* [Okejitu](https://www.alumni.aviation.edu.my/)
* [Kapital4D](https://www.tokobengkalis.id/)
* [Kapital4D](https://www.andreiparabellum.com/)
* [Kapital4D](https://www.tokojatim.id/)
* [Kapital4D](https://television-addiction.com/)
* [Kapital4D](https://ondreaming.org/)
* [Kapital4D](https://www.dominiquetipper.com/)
* [Kapital4D](https://www.colfaxpersimmonfest.com/)
* [Kapital4D](https://www.v60-ost.com/)
* [Kapital4D](https://www.tokobima.id/)
* [Kapital4D](https://www.yess-btc.id/)
* [Kapital4D](https://www.infojuice.org/)
* [CendanaToto](https://www.freesfoods.id/)
* [KapitalSlot](https://osceola564.org/)
* [Kapital4D](https://www.tavanparastar.com/)
* [KapitalSlot](https://www.sindromes.info/)
* [Kapital4D](https://24x7upnews.com/)
* [Kapital4D](https://khalsan.com/)
* [Kapital4D](https://www.yamacparasutufethiye.org/)
* [Cendanatoto](https://afroloaded.com/)
* [Situs Slot Gacor Maxwin](https://takahirony.com/)
* [Pedia288](https://swlaw-alumni.com/)
* [CendanaToto](https://www.tokobone.id/)
* [Pedia288](https://pedia288.id/)
* [CendanaToto](https://www.zambezinewstv.com/)
* [Pedia288](https://pedia228.id/)
* [CendanaToto](https://www.techforgeek.info/)
* [Pedia288](https://www.pedia288.org/)
* [Kapital4D](https://www.dignityhealthsystems.com/)
* [Kapital4D](https://www.kueitu.com/)
* [Pedia288](https://pedia228.org/)
* [Kapital4D](https://thereserve-asia.com/)
* [Pedia288](https://pedia228.com/)
* [KapitalSlot](https://ubiquitousrat.net/)
* [Pedia288](https://www.pedia288.net/)
* [Kapital4D](https://www.tokojayapura.id/)
* [KapitalSlot](https://www.news-jabar.id/)
* [KapitalSlot](https://www.tokocirebon.id/)
* [KapitalSlot](https://www.composeyourselfmag.com/)
* [KapitalSlot](https://www.don-blanding.com/)
* [KapitalSlot](https://www.tokociamis.id/)
* [Kapital4D](https://www.pitchandikulam-herbarium.org/)
* [Kapital4D](https://lkjh.biz/)
* [Rejekibet](https://mobiljateng.com/)
* [KapitalSlot](https://www.whiteipodsappleworld.com/)
* [Kapital4D](https://elm-news.com/)
* [Kapital4D](https://www.ksarsouk.com/)
* [KapitalSlot](https://www.healthcare-xnull.com/)
* [CendanaToto](https://www.waktuini.com/)
* [KapitalSlot](https://dhaarmajaya.com/)
* [Kapital4D](https://kapital4d.com/)
* [CendanaToto](https://apparitiontechnology.com/)
* [Kapital4D](https://seecny-19.org/)
* [Okejitu](https://www.tokobrebes.id/)
* [CendanaToto](https://browsertechnicalsupportnumbers.com/)
* [CendanaToto](https://thailandnow.id/)
* [Slot777](https://bsusos.com/)
* [Slot Gacor](https://kapital4d.id/)
* [Kapital4D](https://www.axis-and-allies.com/)
* [KapitalSlot](https://fourmationentertainment.com/)
* [CendanaToto](https://www.tokobulungan.id/)
* [CendanaToto](https://bjjtech.com/)
* [Kapital4D](https://www.perq-hci.com/)
* [CendanaToto](https://finlandiahealthcentre.com/)
* [CendanaToto](https://junebridesmusic.com/)
* [Kapital4D](https://www.stirling-residencescondo.com/)
* [Slot Gacor 4D](https://kadinsumut.org/)
* [Kapital4D](https://wildlifewalkabout.com/)
* [Pedia288](https://sales-mercedes-benz.id/)
* [Slot 4D](https://womenstorah.com/)
* [CendanaToto](https://www.hariankita.id/)
* [Pedia288](https://www.tokodepok.id/)
* [KapitalSlot](https://www.abudhabi-restaurants.com/)
* [Kapital4D](https://www.hoverbrothers.com/)
* [Slot Online](https://sales-ducati.id/)
* [Slot Gacor 4D](https://www.kadintabalong.org/)
* [CendanaToto](https://acmobilbatam.com/)
* [Toto Slot](https://www.gastonsuarez.org/)
* [CendanaToto](https://www.waktuini.com/)
* [Slot Gacor Maxwin](https://elm-news.com/)
* [Kapital4D](https://fujairahrestoran.com/)
* [Slot Gacor 777](https://www.lasluminarias.com/)
* [Kapitalslot](https://sales-bmw.id/)
* [Slot Gacor 4D](https://www.luwaran.net/)
* [Toto Togel](https://thi.asmo.edu.vn/)
* [Slot Gacor](https://kalpavriksha.ui.ac.id/)
* [Situs Toto](http://u-star.org/)
* [CendanaToto](https://pinescripters.com/)
* [Kapital4D](https://tokenville.tv/)
* [Pedia288](https://www.parqtoken.com/)
* [CendanaToto](https://nettekcoin.com/)
* [KapitalSlot](https://bitrunes.net/)
* [Pedia288](https://www.basedkeren.com/)
* [Okejitu](https://pepycoin.com/)
* [Kapital4D](https://neevadefi.com/)
* [KapitalSlot](https://pumpametti.com/)
* [Pedia288](https://masterchest.info/)
* [Kapital4D](https://kaikeninu.net/)
* [Okejitu](https://www.granc-chain.com/)
* [CendanaToto](https://www.gcnblock.com/)
* [KapitalSlot](https://www.decentra-lotto.com/)
* [Okejitu](https://solomonex.info/)
* [Kapital4D](https://dmmecoin.com/)
* [CendanaToto](https://lotusgang.com/)
* [Pedia288](https://www.safcoinblockexplorer.com/)
* [Okejitu](https://winexplorer.info/)
* [Kapital4D](https://bosradar.com/)
* [PEDIA288](https://sdn4kedonglo.sch.id/)
* [TOTO SLOT](https://www.ghalib.edu.af/)
* [TOTO TOGEL](https://fart.sabu.edu.ly/)
* [CENDANATOTO](https://hecato.com/)
* [Scatter Hitam](https://cv.bvs.hn/)
* [Cendanatoto](https://cyberarea.uz/)
* [Cendanatoto](https://linklist.bio/aksesutama-ct/)
* [Cendanatoto](https://e.gsstore.org/)
* <https://www.cityofnorthfield.org/>
* [Kapital4D](https://www.bmkg-bali.id/)
* [Cendanatoto](https://balenotown.com/)
* [Cendanatoto](https://www.scomo.com/)
* [cendanatoto](https://mptpainavu.ihrd.ac.in/)
* [cendanatoto](https://heylink.me/cendanatoto-login/)
* [cendanatoto](https://firadis.co.jp/)
* [cendanatoto](https://hajij.com/id/images/)
* [cendanatoto](https://pulosari-jombang.web.id/)
* [cendanatoto](https://jurnal.ugm.ac.id/v3/)
* [cendanatoto](https://ugbs.ug.edu.gh/flaa/)
* [Slot Thailand](https://ppid-bpkad.kaltimprov.go.id/)
* [Cendanatoto](http://www.ppgau.ufv.br/en-US)
* [Cendanatoto](https://ihrd.ac.in/)
* [Slot777](https://internal.gakkum.menlhk.go.id/)
* [Cendanatoto](https://basicas.unvm.edu.ar/)
* [Cendanatoto](https://kabkediri.com/)
* [Cendanatoto](https://ppgauel.org/)
* [Slot777](https://internal.gakkum.menlhk.go.id/internal/)
* [toto slot](https://sint.qds.it/)
* [Okejitu](https://www.tokobantul.id/)
* [CendanaToto](https://medianewstoday.com/)
* [Pedia288](https://www.tokopalu.id/)
* [CendanaToto](https://www.tokojawa.id/)
* [KapitalSlot](https://www.tokobandung.id/)
* [Cendanatoto](https://www.tokobekasi.id/)
* [Okejitu](https://newsmadiunni.com/)
* [CendanaToto](https://www.tokoblitar.id/)
* [KapitalSlot](https://www.tokocianjur.id/)
* [Pedia288](https://www.tokobanjar.id/)
* [KapitalSlot](https://hipmipekalongankota.org/)
* [CendanaToto](https://ajmanrestaurants.com/)
* [Kapital4D](https://hipmisumatrautara.org/)
* [rumahpusbin.org](https://rumahpusbin.org/)
* [jurnal-desa.id](https://wwww.jurnal-desa.id/)
* [RSUD Madiun](https://www.rsudmadiun.id/)
* [simakuniga-desa.id](https://www.simakuniga-desa.id/)
* [RSUDBM](https://www.rsudbms.id/)
* [RSUD Ulin Banjarmasin](https://www.rsulin.id/)
* [Tabalongkub](https://tabalongkub.com/)
* Portal Resmi Pemerintah Kabupaten Kota Bogor [Website Resmi Bogor Timur](https://www.bogortimur.id/) Indonesia
* [Madiun](https://madiunni.com/)
* Selamat Datang di [Tabolakkab](https://www.tabolakkab.id/) Resmi Kabupaten Konawe Selatan
* Program Kemitraan Pangan Murah Dan Berkualitas Jaringan [Rumah Pangan Kita](https://rumahpangan.net/) Distribusi Pangan Resmi Peluang Usaha Modal Terjangkau
* Portal Resmi Pemerintah [Direktorat Jenderal Pajak](https://www.pajaknews.com/) Terkini Dan Terpercaya
* [Rita Hazan](https://ritahazan.net/)
* [Potretterkini](https://potretterkini.net/)
* Selamat Datang di Pemerintah Kota Madiun Dan [Kabupaten Madiun](https://www.madium.id/) Indonesia
* [al-ainrestaurants.com](https://al-ainrestaurants.com/)
* RSUD dr.H.Soewondo [Rumah Sakit Umum Kabupaten Kendal](https://rsudkendal.id/) Masyarakat Selalu Hidup Sehat Dan Bahagia
* [Toko-Pedia](https://www.toko-pedia.id/)
* Program Kadin [Kadin Sumatera](https://kadinsumatera.org/) Sistem Informasi Kamar Dagang Industri Indonesia
* [Caplang](https://www.caplang.id/)
* [Buka Lapak](https://www.buka-lapak.com/)
* [Toko Sepatuh](https://www.bata.it.com/)
* Program Kadin [Kadin Sumatera Selatan](https://kadinsumatraselatan.org/) Sistem Informasi Kamar Dagang Industri Indonesia
* [Kadin Sumatra Utara](https://kadinsumatrautara.org/)
k* Berita Daerah[Kota Demak](https://newsdemak.com/) Terkini Dan Terbaru Hari Ini
* Informasi [Berita Kota Madiun](https://www.madiunnews.com/) Terkini dan Terbaru Hari ini
* Rumah Sakit [RS UI](https://www.rsuui.id/) Universitas Indonesia
* SMK SWASTA [BUDHI DARMA INDRAPURA](https://www.smkbudhidarma.id/)
* Reservasi Online [Rumah Sakit Umum RSUD Cicalengka](https://www.rsudcicalengka.id/) Provinsi Jawa Barat
* PEMERINTAH [Kabupaten Tasikmalaya](https://www.tasikmalayakab.com/)
* [Badan Amil Zakat Nasional](https://www.baznaskapuas.com/)
* PEMERINTAH [KABUPATEN KAPUAS](https://www.kapuaskab.com/)
* [Sidbankumda](https://www.hukumsumut.com/)
* [DisnakerTrans](https://www.disnakertrans.com/)
* [Berita Madiun](https://www.madiunnews.com/)
* [KatinganKab](https://katingankab.com/)
* System [Children's National](https://www.childrensnational.id/) Hospital - Ranked Top 10 in the Nation
* Rumah Sakit Kami [Murni Teguh Memorial Hospital](https://www.rsmurniteguh.id/) Kota Jakarta
* Top-ranked Hospital In The Nation [Mayo Clinic](https://www.mayoclinic.id/) Rochester,Minnesota
* Pendaftaran Online [RS Persahabatan](https://www.rsuppersahabatan.id/) Kota Jakarta Timur
* Pelayanan Cepat, Akurat [RS Adam Malik Medan](https://www.rsham.id/) Terjangkau, Efisien, Nyaman
* Rumah Sakit Umum Daerah [(RSUD) Dr. Dradjat Prawiranegara](https://www.rsudserangkab.id/) Kabupaten Serang
* [pafiipalembang.org](https://pafiipalembang.org/)
* [hipmijatengprov.org](https://hipmijatengprov.org/)
* [hipmidemakk.org](https://hipmidemakk.org/)
* [pafiibandung.org](https://pafiibandung.org/)
* [pafitebingtinggii.org](https://pafitebingtinggii.org/)
* [parikotajakarta.org](https://parikotajakarta.org/)
* [parikotalubuklinggau.org](https://parikotalubuklinggau.org/)
* [hipmikotamedan.org](https://hipmikotamedan.org/)
* [parikotalhokseumawe.org](https://parikotalhokseumawe.org/)
* [hipmisiantar.org](https://hipmisiantar.org/)
* [hipmikisarankota.org](https://hipmikisarankota.org/)
* [parikotalangsa.org](https://parikotalangsa.org/)
* [hipmikalimantan.org](https://hipmikalimantan.org/)
* [parikotamakassar.org](https://parikotamakassar.org/)
* [pafiipalembang.org](https://pafiipalembang.org/)
* [hipmikotakediri.org](https://hipmikotakediri.org/)
* [Okejitu](https://hipmikotasolo.org/)
* [parikotabatam.org](https://parikotabatam.org/)
* [Pedia288](https://pafisuntirta.org/)
* [hipmisubangkota.org](https://hipmisubangkota.org/)
* [hipmisumatra.org](https://hipmisumatra.org/)
* [hipmisumatra.org](https://hipmisumatra.org/)
* [parikabpapuabarat.org](https://parikabpapuabarat.org/)
* [Pedia288](https://hipmijawa.org/)
* [hipmisulawesi.org](https://hipmisulawesi.org/)
* [hipmitenggara.org](https://hipmitenggara.org/)
* [hipmisumatraselatan.org](https://hipmisumatraselatan.org/)
* [hipmisumatrabarat.org](https://hipmisumatrabarat.org/)
* [paficabangmedankota.org](https://paficabangmedankota.org/)
* [pafisiabu.org](https://pafisiabu.org/)
* [pafisingkuang.org](https://pafisingkuang.org/)
* [pafiparit.org](https://pafiparit.org/)
* [paritegall.org](https://paritegall.org/)
* [parijawa.org](https://parijawa.org/)
* [paribandahaceh.org](https://paribandahaceh.org/)
* [parikabpapuabarat.org](https://parikabpapuabarat.org/)
* [parikotamedan.org](https://parikotamedan.org/)
* [pariprovmedan.org](https://pariprovmedan.org/)
* [parikotajogja.org](https://parikotajogja.org/)
* [parikotasiantar.org](https://parikotasiantar.org/)
* [parikotapapua.org](https://parikotapapua.org/)
* [paripapuautara.org](https://paripapuautara.org/)
* [Toto Slot](https://casmalampuzha.ihrd.ac.in/)
* [Cendanatoto](https://thssvattamkulam.ihrd.ac.in/)
* [Slot Thailand](https://ppid.dinkop-umkm.jatengprov.go.id/)
* [Pedia288](https://fesur.sabu.edu.ly/)
* <https://kemkespapuaselatan.id/>
* <https://kemkespapuapegunungan.id/>
* <https://kemkespapuatengah.id/>
* [https://kemkespabarprov.id//](https://kemkespabarprov.id/)
* <https://kemkesmalukuprov.id/>
* <https://kemkessultengprov.id/>
* <https://kemkeskalselprov.id/>
* <https://kemkeskaltengprov.id/>
* <https://kemkesbengkuluprov.id/>
* <https://kemkesjambiprov.id/>
* <https://kemkeskepriprov.id/>
* <https://kemkesriau.id/>
* <https://kemkesumbarprov.id/>
* <https://kemkesacehprov.id/>
* <https://simonakemkes.id/>
* <https://jatengprov.org/>
* <https://kotajatengprov.org/>
* <https://jdih-kemkes.id/>
* [BMKG - Badan Meteorologi, Klimatologi, dan Geofisika Indonesia](https://bmkgindonesia.id/)
* [pedia288](https://tupperwareindonesia.id/)
* [pedia288](https://kemkes-kaltim.id/)
* [Cendanatoto](https://ico.sabu.edu.ly/)
* [Toto Slot](https://ihrd.ac.in/libraries/)
* [Slot Gacor](https://www.ug.edu.gh/aad/)
* [Toto Slot Gacor](https://tlm.umg.ac.id/)
* [Slot Gacor 777](https://www.jshiba.net/)
* [Slot Gacor Resmi](https://pepefloki.io/)
* [Situs Slot88 Gacor](https://www.lenny-coin.com/)
* [Slot Bet 200 Perak](https://ordynals.com/)
* [Slot Online Resmi](https://www.yangdividend.com/)
* [Slot Online Gacor](https://icorank.info/)
* [Slot Bet 200 Resmi](https://www.seyblock.com/)
* [Slot Gacor 777](https://www.jadecurrency.com/)
* [Slot Thailand Resmi](https://tgichain.com/)
* [Slot Gacor 4D](https://czpegs.com/)
* [Slot Online Gacor](https://www.vemarhelmets.net/)
* [Slot Online Terbaru](https://www.chrismouldink.com/)
* [Slot Modal Receh](https://withoutdoctor.net/)
* [Slot Banjir Maxwin](https://www.weathermtaani.com/)
* [Slot Online](https://themmsstore.com/)
* [Slot Online Gacor](https://www.confectionscarcajou.com/)
* [Slot Gacor 777](https://trimbot2020.org/)
* [Slot Thailand](https://www.oecd-5wf.mx/)
* [Slot Pulsa](https://www.energy-infrastructure-forum.com/)
* [Slot Scatter Hitam](https://dimitrad.com/)
* [Slot Gacor 4D](https://aobing.uk.com/)
* [Slot Super Gacor](https://www.3dneonet.org/)
* [Slot Thailand](https://www.life-ramses.com/)
* [Slot Online](https://www.goma-organic.org/)
* [Cendanatoto](https://sostermitas.angra.uac.pt/)
* [batiktoto](https://heylink.me/batiktoto/)
* [Kapitalslot](https://tas.sabu.edu.ly/)
* [Cendanatoto](https://remuneraciones.unap.edu.pe/remu/)
* [Okejitu](https://feps.sabu.edu.ly/en)
* [Slot Gacor 2025](https://www.vankahvalti-evi.com/)
* [Bandar Toto Resmi](https://restaurant-puccini.com/)
* [Slot Gacor](https://cyhacker.com/)
* [Slot Online](https://zooabidjan.org/)
* [Slot88](https://asspornpics.info/)
* [Situs Slot Gacor](https://www.divingleisurelondon.co.uk/)
* [Slot88](https://www.any-sound-recorder.com/)
* [Slot Bet 200](https://www.martineau-pr.com/)
* [Slot Bet Kecil](https://soysierragorda.com/)
* [Slot Gacor 2025](https://www.blissmaui.com/)
* [Slot Gacor Hari Ini](https://the-jungle-negril.com/)
* [Slot Online](https://alleganyexpeditions.com/)
* [Slot Scatter Hitam](https://www.mediterraneancafe-flatiron.com/)
* [Slot777](https://www.karavan-gallery.com/)
* [Slot Gacor 2025](https://www.kestorinn.com/)
* [Slot Gacor](https://www.morrodocareca.org/)
* [Slot Dana](https://www.amigosbistro.com/)
* [Okejitu](https://www.saint-sinner.net/)
* [Kapital4D](https://www.indu-art.org/)
* [CendanaToto](https://www.kevinmanderville.net/)
* [Kapital4D](https://www.stgholborn.org/)
* [CendanaToto](https://mattonimages.com/)
* [Kapital4D](https://knot35.com/)
* [CendanaToto](https://shestreamsconference.com/)
* [Kapital4D](https://crystallography-online.com/)
* [CendanaToto](https://www.jahsound.net/)
* [Kapital4D](https://www.petigre.com/)
* [CendanaToto](https://www.ghost-writer-book.com/)
* [Kapital4D](https://themukiwa.com/)
* [CendanaToto](https://www.myinternalreferral.com/)
* [Kapital4D](https://www.destination-cook-islands.com/)
* [CendanaToto](https://www.saveideastap.com/)
* [Kapital4D](https://sunnahway.net/)
* [CendanaToto](https://www.topolovgrad.net/)
* [Kapital4D](https://nashzhitomir.net/)
* [CendanaToto](https://arezou.org/)
* [Kapital4D](https://www.asfli.org/)
* [Cendanatoto](http://socupt.freehostia.com/)
* [Cendanatoto](https://mimoplay.ru/)
* [Bandar Togel Terpercaya](https://news.ganesa.or.id/)
* [Slot Gacor](https://nuct.edu.jo/)
* [CENDANATOTO](https://blog.morphmaternity.com/)
* [SLOT777](https://satpolpp.tabanankab.go.id/)
* [SLOT MAXWIN](https://dprd.padangsidimpuankota.go.id/)
* [Cendanatoto](https://conteudo.camarariobrilhante.ms.gov.br/)
* [Cendanatoto](https://www.gravity.gr/)
* [Slot Gacor](https://jurnal.ugm.ac.id/v3/controllers/)
* [CENDANATOTO](https://pesaflash.hogi.edu.bi/)
* [CENDANATOTO](https://ugelhuanta.gob.pe/)
* [CENDANATOTO](https://sys.abdullaheldeep.com/)
* [CENDANATOTO](https://diya.vaks.org.ua/)
* [fixtoto](https://heylink.me/fixtoto/)
* [Cendanatoto](https://rhdc.gov.jo/)
* [Prediksi Hk](https://heylink.me/prediksihk2/)
* [RUPIAHSLOT](https://heylink.me/rupiahslot2/)
* [CENDANATOTO](https://cce.iperecoe.edu.ng/)
* [CENDANATOTO](https://didactic.unitbv.ro/)
* [TOTO SLOT](https://untama.ac.id/)
* [Lohanslot](https://lohanjuara.com/)
* [Lohanslot](https://lohanslotresmi.com/)
* [Cendanatoto](https://easyparcel.co.id/)
* [Kapital4D](https://swap.czpegs.com/)
* [Kapital4D](https://www.khudipakistan.com/)
* [CendanaToto](https://www.jewels-gems-clocks-watches.com/)
* [CendanaToto](https://www.udotsi-nord.net/)
* [KapitalSlot](https://docs.bitrunes.net/)
* [Kapital4d](https://heylink.me/peterpaypal)
* [Slot Gacor](https://www.devalt.org/)
* [Cendanatoto](https://somebitchtoldme.com/)
* [Cendanatoto](https://blog.mercaypublicidad.ibero.mx/)
* [Cendanatoto](https://www.nettcentury.com.br/)
* [Cendanatoto](https://www.uhs-jo.com/)
* [Cendanatoto](https://ctl.eap.gr/)
* [Cendanatoto](https://events.arab-board.org/)
* [Cendanatoto](https://linklist.bio/cendanajitu/)
* [Cendanatoto](https://www.kemkessumut.id/)
* [Cendanatoto](https://www.bmkgindonesia.id/)
* [Cendanatoto](https://postcomp.ciens.ucv.ve/)
* [CENDANATOTO](https://agra.org/)
* [Cendanatoto](https://www.nuct.edu.jo/)
* [Kapital4d](https://www.kudosintech.com/)
* <https://quotespics.com/category/humor/>
* [Kapital4d](https://ai.ultimatemultimediaconsult.com/)
* [Bolahoki](https://v1.ppgauel.org/)
* [BolaHoki](https://linklist.bio/bolahoki/)
* [Cendanatoto](https://csu.ase.ro/)
* [Toto Slot](https://ejer.com.tr/volume-view/)
* [Bandar Togel](https://agra.org/news/svalbard-global-seed-vault-receives-big-seed-deposit/)
* [CENDANATOTO](https://uch-ibadan.org.ng/information/)
* [CENDANATOTO](https://uch-ibadan.org.ng/)
* [CENDANATOTO](https://cendanatoto.io/)
* [Cendanatoto](https://archstorytelling.fa.ulisboa.pt/author/archstorystelling-firmroad-pt/)
* [Slot777](https://gizi.poltekkespalembang.ac.id/)
* [Cendanatoto](https://mymookh.com/contact-us/)
* [Cendanatoto](https://wilsonchildrensfund.com/about-us)
* [Toto Slot](https://satpolpp.tabanankab.go.id/pegawai/)
* [Cendanatoto](https://servidores.chia-cundinamarca.gov.co/edl/)
* [Cendanatoto](https://art-industriel.fr/)
* [Cendanatoto](https://www.cercp.org/)